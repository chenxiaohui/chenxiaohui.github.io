<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[CXH.ME]]></title>
  <link href="http://cxh.me/atom.xml" rel="self"/>
  <link href="http://cxh.me/"/>
  <updated>2016-06-18T20:22:07+08:00</updated>
  <id>http://cxh.me/</id>
  <author>
    <name><![CDATA[Harry Chen]]></name>
    <email><![CDATA[sdqxcxh@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ccache和cgo并存的问题]]></title>
    <link href="http://cxh.me/2016/06/18/ccache-and-cgo/"/>
    <updated>2016-06-18T20:15:00+08:00</updated>
    <id>http://cxh.me/2016/06/18/ccache-and-cgo</id>
    <content type="html"><![CDATA[<p>   ccache是加快编译的神器，有了ccache，忘了distcc。但是发现go和c混编的项目里面如果用了cgo的话，go编译的时候ccache会报错。主要是传给ccache的某些参数ccache不认识。错误如下：</p>

<pre><code>/usr/bin/ccache: invalid option -- 'd'
Usage:
    ccache [options]
    ccache compiler [compiler options]
    compiler [compiler options] (via symbolic link)

Options:
    -c, --cleanup delete old files and recalculate size counters
                          (normally not needed as this is done automatically)
    -C, --clear clear the cache completely
    -F, --max-files=N set maximum number of files in cache to N (use 0 for
                          no limit)
    -M, --max-size=SIZE set maximum size of cache to SIZE (use 0 for no
                          limit; available suffixes: G, M and K; default
                          suffix: G)
    -s, --show-stats show statistics summary
    -z, --zero-stats zero statistics counters

    -h, --help print this help text
    -V, --version print version and copyright information

See also &lt;http://ccache.samba.org&gt;.
dpkg-architecture: warning: Couldn't determine gcc system type, falling back to default (native compilation)
</code></pre>

<p>  之前都是关了ccache，后来想新的版本能不能搞定呢？有人提了Issue但是没看到release上有啥新的fix。直接升了一下版本：</p>

<pre><code>wget https://www.samba.org/ftp/ccache/ccache-3.2.5.tar.bz2
bunzip2 ccache-3.2.5.tar.bz2
tar xvf ccache-3.2.5.tar
cd ccache
./autogen.sh
./configure
make -j 8
yum install asciidoc
make install
</code></pre>

<p>   发现还是一样。后来想可以用shell包一层啊，看<a href="https://bbs.archlinux.org/viewtopic.php?id=204639" title="ccache does not work with nvcc (CUDA)">网上</a>有相应的方案：</p>

<pre><code> #!/bin/bash
 ccache gcc "$@"
</code></pre>

<p>   貌似这样ccache不认识的参数就不传递了？反正是ok了，改天研究下。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用nfs挂载网络磁盘]]></title>
    <link href="http://cxh.me/2016/06/17/export-disk-using-nfs/"/>
    <updated>2016-06-17T11:58:00+08:00</updated>
    <id>http://cxh.me/2016/06/17/export-disk-using-nfs</id>
    <content type="html"><![CDATA[<p>  分布式环境下经常需要到各个节点启动server，常见的方式推的方式，比如scp到各个结点，但是有时候更新的文件少儿需要scp的文件比较多。这时候可以选择nfs挂载的方式把编译好的文件放到网络磁盘上，然后共享到其他的服务器，这样可以按需使用。</p>

<p>  首先配置一下nfs服务器。假设系统都是centos：</p>

<pre><code>yum install -y nfs-utils
yum install -y portmap
rpm -qa | grep nfs
</code></pre>

<p>  事实上看centos6.5以上portmap应该被rpcbind替代了，而已安装nfs-utils的时候应该顺便安装了rpcbind。之后配置一下需要挂载的磁盘：</p>

<pre><code>文件/etc/exports:
/tmp rz*(rw,async) yf*(ro)
</code></pre>

<p>  简单解释一下： /tmp是挂载的目录路径，后面跟权限控制，可以是主机名或者ip，rz*表示rz开头的主机，括号里面是权限。整条语句表示把/tmp目录共享以rw权限和async方式共享给rz开头的机器，同时以ro权限共享给yf开头的机器。其他属性可以参考<a href="http://www.liusuping.com/ubuntu-linux/Redhat-Linux-NFS-setting.html" title="Redhat Linux下NFS的配置及操作">这里</a>:</p>

<p>  之后启动nfs服务：</p>

<pre><code>service nfs start
</code></pre>

<p>  需要挂载机器上同样安装客户端：</p>

<pre><code>yum install -y nfs-utils
</code></pre>

<p>  挂载到指定的目录：</p>

<pre><code>mkdir fs &amp;&amp; mount -t nfs xxx.xxx.xx.xx:/tmp ./fs
</code></pre>

<p>  xxx指定机器名或者ip</p>

<h3>参考文献:</h3>

<blockquote><p>[1] Redhat Linux下NFS的配置及操作, <a href="http://www.liusuping.com/ubuntu-linux/Redhat-Linux-NFS-setting.html">http://www.liusuping.com/ubuntu-linux/Redhat-Linux-NFS-setting.html</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[跨线程解锁安全的spinlock]]></title>
    <link href="http://cxh.me/2016/06/13/safe-spin-lock/"/>
    <updated>2016-06-13T17:36:00+08:00</updated>
    <id>http://cxh.me/2016/06/13/safe-spin-lock</id>
    <content type="html"><![CDATA[<p>  在C语言下面我们可能会写出如下的代码：</p>

<pre><code>static pthread_spinlock_t lock;

__attribute__((constructor))
void lock_constructor () {
    if ( pthread_spin_init ( &amp;lock, 0 ) != 0 ) {
        exit ( 1 );
    }
}

int func(xx) {
  int ret = 0;
  if (xx) {
    ret = ERR1;
    goto exit;
  }
  pthread_spin_lock(&amp;lock);
  if (xx) {
    ret = ERR2;
    goto exit;
  }
exit:
  pthread_spin_unlock(&amp;lock);
  return 0;
}

__attribute__((destructor))
void lock_destructor () {
    if ( pthread_spin_destroy ( &amp;lock ) != 0 ) {
        exit ( 3 );
    }
}
</code></pre>

<p>  这段代码存在下面几个问题：</p>

<pre><code>1. spinlock没有静态初始化函数，需要确保使用前调用了pthread_spin_init.
2. 跳转到exit标记去unlock的时候，并不能保证lock已经被加过锁了。
3. func本身存在潜在的并发问题，一个线程可能跳转到exit去解别的线程加的锁。
</code></pre>

<p>  根据<a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_spin_lock.html" title="The Open Group Base Specifications Issue 6 IEEE Std 1003.1, 2004 Edition">文档</a>这几种情况下的行为是未定义的。</p>

<pre><code>  The pthread_spin_lock() function shall lock the spin lock referenced by lock. The calling thread shall acquire the lock if it is not held by another thread. Otherwise, the thread shall spin (that is, shall not return from the pthread_spin_lock() call) until the lock becomes available. The results are undefined if the calling thread holds the lock at the time the call is made. The pthread_spin_trylock() function shall lock the spin lock referenced by lock if it is not held by any thread. Otherwise, the function shall fail.

  The results are undefined if any of these functions is called with an uninitialized spin lock.
</code></pre>

<p>  为了情况1，我们可以考虑通过原子操作实现spin_lock，用一个volatile int64类型的整数来标识当前锁的状态。nginx里面的实现如下：</p>

<pre><code>    /* 
     * Copyright (C) Igor Sysoev 
     * Copyright (C) Nginx, Inc. 
     */  


    #include &lt;ngx_config.h&gt;  
    #include &lt;ngx_core.h&gt;  

    //Function: to achieve spin atomic operation lock method based on ngx_spinlock  
    //Parameter interpretation:   
    //lock: Lock the atomic variable expression  
    //value: Flag, whether the lock is a process  
    //spin: In a multi processor system, when the ngx_spinlock method did not get the lock, the current process in a scheduling kernel in the waiting for the other processors to release the lock time  
    void  
    ngx_spinlock(ngx_atomic_t *lock, ngx_atomic_int_t value, ngx_uint_t spin)  
    {  

    #if (NGX_HAVE_ATOMIC_OPS)//Support atomic operations  

        ngx_uint_t  i, n;  

        //Has been in circulation, until the lock is acquired  
        for ( ;; ) {  

            //Lock 0 said no other process holding the lock, then the lock value indicates the current process holding the lock is set to value parameters  
            if (*lock == 0 &amp;&amp; ngx_atomic_cmp_set(lock, 0, value)) {  
                return;  
            }  

            //If it is a multi processor system  
            if (ngx_ncpu &gt; 1) {  
                for (n = 1; n &lt;spin; n &lt;&lt;= 1) {  
                    //With the increasing number of the actual to wait, inspection interval and lock more  
                    for (i = 0; i &lt;n; i++) {  
                        ngx_cpu_pause();//Tell CPU now in the spin lock wait state  
                    }  

                    //Check the lock is released  
                    if (*lock == 0 &amp;&amp; ngx_atomic_cmp_set(lock, 0, value)) {  
                        return;  
                    }  
                }  
            }  

            //The current process for the processor, but still in the executable state  
            ngx_sched_yield();  
        }  

    #else  

    #if (NGX_THREADS)  

    #error ngx_spinlock() or ngx_atomic_cmp_set() are not defined !  

    #endif  

    #endif  

    }       
</code></pre>

<p>  简单解释几个关键点：</p>

<ol>
<li> ngx_atomic_cmp_set等是nginx封装的原子操作，可以从字面意思理解。能直接对应到gcc支持的一些原子操作。</li>
<li> ngx_cpu_pause是不切换cpu上下文的让cpu让出时间片的操作，可对应到后文的<strong>asm</strong>(&ldquo;.byte 0xf3, 0x90&rdquo;);</li>
<li> ngx_sched_yield 暂时挂起上下文，让cpu调度其他任务。</li>
</ol>


<p>  nginx的实现解决了静态初始化的问题，但是解决不了上述问题2和3。为此我们可以考虑在表征spinlock状态的整形变量中加入线程id，来区分操作者是否是锁持有者。参考实现如下：</p>

<pre><code>typedef volatile int64_t Atomic;

#define _spin_unlock_safe   _unlock_safe

typedef struct {
 union {
  struct {
    int32_t tid;
    int32_t atomic32;
  };
  volatile int64_t atomic;
 };
} CACHE_ALIGNED SpinLock;

static __inline__ int64_t _get_tid() {
  static __thread int64_t tid = -1;
  if _unlikely(tid == -1) {
    tid = (int64_t)(syscall(__NR_gettid));
  }
  return tid;
}

static __inline__ int _try_lock_safe(SpinLock *lock) {
  SpinLock lock_val = };
  return lock-&gt;atomic == 0 &amp;&amp; _atomic_cmp_set(&amp;lock-&gt;atomic, 0, lock_val.atomic);
}

static __inline__ int _unlock_safe(SpinLock *lock) {
  SpinLock lock_val = };
  return _atomic_cmp_set(&amp;lock-&gt;atomic, lock_val.atomic, 0);
}

static __inline__ void _spin_lock_safe(SpinLock *lock) {
  int i, n;
  SpinLock lock_val = };
  for (; ;) {
    if (lock-&gt;atomic == 0 &amp;&amp; _atomic_cmp_set(&amp;lock-&gt;atomic, 0, lock_val.atomic)) {
      return;
    }

    for (n = 1; n &lt; 1024; n &lt;&lt;= 1) {

      for (i = 0; i &lt; n; i++) {
        __asm__(".byte 0xf3, 0x90");
      }

      if (lock-&gt;atomic == 0 &amp;&amp; _atomic_cmp_set(&amp;lock-&gt;atomic, 0, lock_val.atomic)) {
        return;
      }
    }

    sched_yield();
  }
}

static __inline__ void _spin_lock(Atomic *lock) {
  int i, n;
  for (; ;) {
    if (*lock == 0 &amp;&amp; _atomic_cmp_set(lock, 0, 1)) {
      return;
    }

    for (n = 1; n &lt; 1024; n &lt;&lt;= 1) {

      for (i = 0; i &lt; n; i++) {
        __asm__(".byte 0xf3, 0x90");
      }

      if (*lock == 0 &amp;&amp; _atomic_cmp_set(lock, 0, 1)) {
        return;
      }
    }

    sched_yield();
  }
}
</code></pre>

<p>  简单解释几个问题：</p>

<ol>
<li> <strong>asm</strong>(&ldquo;.byte 0xf3, 0x90&rdquo;);是intel的一条指令，实际上就是上面的ngx_cpu_pause</li>
<li> sched_yield实现等同于ngx_sched_yield</li>
<li> 用两个int32拼成了一个64位整数，考虑截取了tid有风险，后期可以优化成只用一位表示加锁状态，剩下63位依然给tid用。</li>
</ol>


<h3>参考文献:</h3>

<blockquote><p>[1] The Open Group Base Specifications Issue 6 IEEE Std 1003.1, 2004 Edition, <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_spin_lock.html">http://pubs.opengroup.org/onlinepubs/009695399/functions/pthread_spin_lock.html</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[有关coredump没有符号的问题]]></title>
    <link href="http://cxh.me/2016/06/06/glibc-no-symbol-problem/"/>
    <updated>2016-06-06T15:02:00+08:00</updated>
    <id>http://cxh.me/2016/06/06/glibc-no-symbol-problem</id>
    <content type="html"><![CDATA[<p>  线上server core掉了，看dmesg能看到core的日志，</p>

<pre><code>s3store[16586]: segfault at 2a28000 ip 00007fda20543b58 sp 00007fd9e9894128 error 4 in libc-2.12.so[7fda204ba000+18a000]
</code></pre>

<p>  但是/proc/sys/kernel/core_pattern指向的位置并没有core文件，改一下core_pattern再跑应该能core出来，不过并不是稳定复现的。所以只能先凭这条日志来分析了。从core的位置看，大概率应该是malloc里面的问题。用</p>

<pre><code>addr2line -e xxx  00007fda20543b58
</code></pre>

<p>  看到的结果是??:0。怀疑是glibc没有调试信息。看一下系统的glibc版本：</p>

<pre><code>rpm -qa |grep glibc
glibc-common-2.12-1.166.el6_7.7.x86_64
glibc-static-2.12-1.166.el6_7.7.x86_64
glibc-2.12-1.166.el6_7.7.x86_64
glibc-devel-2.12-1.166.el6_7.7.x86_64
glibc-debuginfo-common-2.12-1.166.el6_7.7.x86_64
glibc-headers-2.12-1.166.el6_7.7.x86_64
glibc-debuginfo-2.12-1.166.el6_7.7.x86_64
</code></pre>

<p>  去centos网站上下对应版本的glibc debuginfo并安装</p>

<pre><code>http://debuginfo.centos.org/6/x86_64/
wget http://debuginfo.centos.org/6/x86_64/glibc-debuginfo-2.12-1.166.el6_7.7.x86_64.rpm
wget http://debuginfo.centos.org/6/x86_64/glibc-debuginfo-common-2.12-1.166.el6_7.7.x86_64.rpm
rpm -ivh glibc-debuginfo-common-2.12-1.166.el6_7.7.x86_64.rpm
rpm -ivh  glibc-debuginfo-2.12-1.166.el6_7.7.x86_64.rpm
</code></pre>

<p>  之后继续addr2line -e xxx 00007fda20543b58还是没有&hellip;</p>

<p>  我擦嘞。改天继续。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[union和struct相互嵌套时的初始化]]></title>
    <link href="http://cxh.me/2016/05/26/union-struct-initialize/"/>
    <updated>2016-05-26T11:01:00+08:00</updated>
    <id>http://cxh.me/2016/05/26/union-struct-initialize</id>
    <content type="html"><![CDATA[<pre><code>typedef union {
volatile int64_t atomic;
    struct{
      int32_t pid;
      int32_t atomic32;
    };
} S3Atomic;

int main(int argc, const char *argv[]) {
    S3Atomic atomic = ;
    printf("%x\n", atomic.pid);
    printf("%x\n", atomic.atomic32);
    printf("%lx\n", atomic.atomic);
    return 0;
}
</code></pre>

<p><a href="http://smilejay.com/2011/12/gcc_union_in_struct/" title="联合体(UNION)在结构体(STRUCT)中的初始化（GCC语法）">参考如下代码</a></p>

<pre><code>/* 
 * This sample shows definition and initiation of a struct and a union in a struct.
 * using GCC to compile this C file
 * Author: Jay Ren 
*/

#include &lt;stdio.h&gt;

int main(int argc, char *argv[]) {
    struct my_struct1 {
        int num1;
        union {
            int num2;
            char ch;
        };
    };

    struct my_struct1 my_st1 = {
        .num1 = 111,
        /* the following commented line will cause a syntax error. */
        /* .num2 = 123456,*/
    };

    /* num2 or ch in the union of the struct can't be initiated before. */
    my_st1.num2 = 123456;

    printf("my_st1.num1 = %d\n", my_st1.num1);
    printf("my_st1.num2 = %d\n", my_st1.num2);

    struct my_struct2 {
        int num1;
        union my_union {
            int num2;
            char ch;
        } my_u;
    };

    struct my_struct2 my_st2 = {
        .num1 = 222,
        /*  the following line for initiating num2 works fine. */
        .my_u.num2 = 123456,
    };

    printf("my_st2.num1 = %d\n", my_st2.num1);
    printf("my_st2.num2 = %d\n", my_st2.my_u.num2);

    return 0;
}
</code></pre>

<h3>参考文献:</h3>

<blockquote><p>[1] 联合体(UNION)在结构体(STRUCT)中的初始化（GCC语法）, <a href="http://smilejay.com/2011/12/gcc_union_in_struct/">http://smilejay.com/2011/12/gcc_union_in_struct/</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[logrotate版本问题]]></title>
    <link href="http://cxh.me/2016/05/18/loglogrotate-version-problem/"/>
    <updated>2016-05-18T16:02:00+08:00</updated>
    <id>http://cxh.me/2016/05/18/loglogrotate-version-problem</id>
    <content type="html"><![CDATA[<p>  线上运维过程中切日志用了logrotate，但无奈日志打的太多，一天的日志几十G难以分析，遂决定改成每小时切分一次日志。从logrotate的说明看有hourly的支持，但是直接把daily改成hourly之后启动报错：</p>

<pre><code>unknown option 'hourly'
</code></pre>

<p>  感觉是logrotate 3.8.7的版本不支持hourly语法</p>

<p>  rpm安装logrotate高版本的包提示缺少fillup和其他的依赖，同时glibc的版本也要求高版本。于是下载了logrotate的源码安装，以最新版本3.9.2为例</p>

<pre><code>./autogen.sh
./configure
</code></pre>

<p>  提示缺少libpopt头文件，下载了libpopt 1.5的源码安装，提示libtool版本不对。我擦嘞。</p>

<p>  后来突然想到libpopt是debian下的命名，试一下centos下</p>

<pre><code>yum install popt-devel -y
</code></pre>

<p>  搞定。于是继续源码安装，直接用logrotate的官网版本好了。</p>

<pre><code>yum install popt-devel -y
wget https://fedorahosted.org/releases/l/o/logrotate/logrotate-3.8.6.tar.gz
tar zxvf  logrotate-3.8.6.tar.gz
cd logrotate-3.8.6 &amp;&amp; make &amp;&amp; make install
</code></pre>

<p>  这个版本是可以稳定使用的。中间试了几个别的版本，3.8.3还是不支持hourly语法，3.8.5支持了语法，但是测试的时候</p>

<pre><code>logrotate -d /etc/logrotate.conf
</code></pre>

<p>  有core，跟进源码去感觉是依赖bug，换到3.8.6终于ok了&hellip;回去看作者更新日志：</p>

<pre><code>3.8.4 -&gt; 3.8.5
     - Improved rotation during daylight saving time and between timezone
       changes.
     - Fixed ACL setting problem caused by ext3 erroneously reporting ENOSYS
       instead of ENOSUP.
     - Do not continue with rotation if state file is corrupted.
     - Make logrotate.status creation atomic.
     - Allow "hourly" rotation. See manpage for more information.
     - Use "/bin/echo" in tests. Fixes tests execution in Dash.
     - Do no try to parse config files bigger than 16MB.
     - Improved manpage consistency and formatting.
     - Fix race condition between acl_set_fd() and fchmod().
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[迷失在时间里]]></title>
    <link href="http://cxh.me/2016/05/15/lost-in-time/"/>
    <updated>2016-05-15T23:34:00+08:00</updated>
    <id>http://cxh.me/2016/05/15/lost-in-time</id>
    <content type="html"><![CDATA[<p>   好久没写写自己心里的感受了。大概自从毕业工作之后，每天忙很多的事情，就不再有心情去体会一些事情。习惯了忙碌于工作，在这个城市的街头、地铁和公交站穿行，每天想的是五环的房价、今天有没有雾霾和路上堵不堵，只有夜深人静的时候才会想起以前的日子。</p>

<p>   想起北航的参天大树，想起以前的同学，想起清华的荷塘，想起校园里美好的日子和可爱的女生，想起晚上安静的校园和校园外的车水马龙。大学的生活确实是人生最美好的几年，让你无论什么时候回想起来都觉得心底柔软、岁月静好。</p>

<p>   有时候觉得自己迷失在时间里了。每天早晨醒来，想的都是匆匆逝去的时间和忙不完的事情。停下脚步，听见风穿过的声音，才觉得时间的洪流里面，也有这些许的温存，有难得的避风港，让灵魂停下来歇息一下。哎，我曾经是多么感性的一个人啊&hellip;</p>

<p>   物是人非。尽量不去想这些事情。每每回忆以前都觉得会触动心里的痛点，看时光匆匆流去，那些逝去的画面，变得越发模糊，而又无可奈何。于是习惯了让工作占据思想，理性太多而湮没感性，这如何又不是一种躯壳。生活节奏已经进入快车道，每每停下来的时候都会觉得不安，这偶然的感性就变得异常奢侈。</p>

<p>   入夜。这座熟悉而陌生的城市，又一次慢慢进入梦乡。同一面蓝天下的人啊，有人睡去，有人醒着，有人睡不着。窗外灯火阑珊，寂寞的人，愿你在时光中找到温暖。</p>

<p>   <img class="img-polaroid center" src="http://cxh.me/images/2016/campus.jpg"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[dirname和basename的一些细节]]></title>
    <link href="http://cxh.me/2016/05/15/dirname-and-basename-cautions/"/>
    <updated>2016-05-15T14:42:00+08:00</updated>
    <id>http://cxh.me/2016/05/15/dirname-and-basename-cautions</id>
    <content type="html"><![CDATA[<p>  作为获取文件名和文件路径的函数，dirname和basename的签名是：</p>

<pre><code>#include &lt;libgen.h&gt;

char *dirname(char *path);

char *basename(char *path);
</code></pre>

<p>  之前没注意的地方是这个函数的输入输出都不是const的，也就意味着这个函数调用过程可能会修改char*指向的string内容。所以直接输出一个不可变字符串是不行的，同理，也要考虑这个非const函数会破坏入参。也就是：</p>

<pre><code>char *str = "/abc/def";
printf("%s\n", dirname(str));
</code></pre>

<p>  会core掉。而</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;libgen.h&gt;
int main(int argc, const char *argv[]) {
  char str[] = "/abc/def";
  printf("%s\n", dirname(str));
  printf("%s\n", basename(str));
  printf("%s\n", str);
  return 0;
}
</code></pre>

<p>  输出结果是：</p>

<pre><code>/abc
abc
/abc
</code></pre>

<p>  还有一个更有意思的问题&hellip;.如果对同一个path先后调用dirname和basename，那么返回的只有一个是对的&hellip;.因为源已经被修改了。反过来可以。</p>

<p>  path在执行过程中被修改了。C系的函数很多面临这个问题，如果不这么做的话要申请一块额外的内存，然后返回，而释放这块内存的工作得调用方完成，这种情况下，内存泄露的可能性很大，所以很多c库函数的选择是用全局变量（getopt等)或者修改入参（basename等）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据库锁和隔离级别的总结]]></title>
    <link href="http://cxh.me/2016/04/03/summarize-isolation-lock/"/>
    <updated>2016-04-03T19:34:00+08:00</updated>
    <id>http://cxh.me/2016/04/03/summarize-isolation-lock</id>
    <content type="html"><![CDATA[<p>  最近在琢磨MVCC和悲观乐观锁的问题，感觉有些以前学习的点没有串联起来，主要是隔离级别和锁相关的，这里总结思考一下：</p>

<ol>
<li><p> 两阶段锁解决了什么问题</p>

<p>两阶段锁主要解决事务调度的可串行化，保证了调度是正确的。一个简单的例子参考<a href="http://baike.baidu.com/view/3798716.htm" title="两阶段封锁">度娘</a>这里。</p></li>
<li><p> 实现两阶段锁对应了什么隔离级别。</p>

<p>两阶段锁保证了基本的隔离级别正确性，RC之上的隔离级别（包含RC）都需要至少保证两阶段锁。一个例外是如果where条件不走索引的话，是可能全表加锁的，这种情况下mysql为了性能提前解锁了不满足条件的行，参见<a href="http://hedengcheng.com/?p=771#_Toc374698312" title="MySQL 加锁处理分析">这里</a>。</p></li>
<li><p> 各个隔离级别对应的加锁策略。</p>

<p>这个比较简单了：</p>

<ul>
<li>RU：读加S锁，写加X锁，完成即可释放。</li>
<li>RC：读加S锁，写加X锁，读锁完成可释放，写锁一直到事务完成再释放。</li>
<li>RR：读加S锁，写加X锁，读写锁都一直到事务完成再释放。</li>
<li>SE: RR基础上再加范围锁。</li>
</ul>
</li>
<li><p> select如何防止丢失更新。</p>

<p>按照<a href="http://hedengcheng.com/?p=771#_Toc374698312" title="MySQL 加锁处理分析">何登成</a>博客里面的定义，可以区分MVCC下两种读。</p>

<p>快照读</p>

<ul>
<li>select * from table where ?;</li>
</ul>


<p>当前读。</p>

<ul>
<li>select * from table where ? lock in share mode;</li>
<li>select * from table where ? for update;</li>
<li>insert into table values (…);</li>
<li>update table set ? where ?;</li>
<li>delete from table where ?;</li>
</ul>


<p>快照读级别下，写事务可能丢失更新，因为select并不阻塞写，两个读写事务可能基于同一个快照点。当前读级别下，写阻塞读，所以涉及同一行的读写事务一定是串行的。不会丢失更新。</p>

<p>基于乐观锁的方式下，也不会丢失更新，因为检查到更新可能被覆盖的操作都会回滚（打回重试）了。</p></li>
<li><p> MVCC和锁（悲观乐观）的实现方式下，隔离级别是怎么实现的？</p>

<p>MVCC主要针对冲突数据的处理，乐观锁、悲观锁决定了最终原子的更新一行的方式。</p>

<p>MVCC加乐观锁的方式基本思路如下：</p>

<blockquote><p>定义一个keyValueSet，Conditional Update在此基础上加上了一组更新条件conditionSet { … data[keyx]=valuex, … }，即只有在D满足更新条件的情况下才将数据更新为keyValueSet’；否则，返回错误信息。<a href="http://coolshell.cn/articles/6790.html" title="多版本并发控制(MVCC)在分布式系统中的应用">引用</a></p></blockquote>

<p>MVCC加悲观锁主要是提供了不加锁的读。按<a href="http://hedengcheng.com/?p=771#_Toc374698312" title="MySQL 加锁处理分析">何登成</a>的文章里看，就是快照读+当前读。快照读级别下，直接按照版本读就行，当前读级别下，如果有锁冲突还是要加锁。</p>

<p>在ob里的实现上看比较明显，行的修改增量组织为一棵B树，历史版本表现为B树叶子节点上挂的链表。链表的按照版本号串接起所有历史版本，全局Publish version决定了当前可见的最新版本。</p>

<p>在快照读级别下，select不需要加锁，只需要每次按照publish version去链表遍历，找到可见的结果并返回。如果不修改transaction consistency set的情况下，这种读取可能导致两次读结果不一致，不满足RR或者SI(Snapshot Isolation)。OB0.5增加了一个readonly snapshot的级别，可以提供对一个快照的只读操作，保证了多次读取的一致，但是没有snapshot级别不加锁的读写事务（快照写），毕竟基于一个旧的快照做写操作可能使新的提交丢失。这里要么类似乐观锁验证一下版本，要么加锁来延迟读写。</p>

<p>当前读级别下，select也要加锁直到事务结束释放，跟mysql的实现一致。</p>

<p>总结来讲，如果把当前读看成写事务的话，那么ob事实上是读操作只看版本号，写操作只看锁。如果只考虑当前读和写操作的话，那么相当于有冲突的时候读锁延迟了写操作，写锁延迟了读操作，保证了调度的串行。这种情况下，多次读取的结果是一致的。</p></li>
<li><p> select for update在mvcc下如何实现。</p>

<p>道理是一样的，跟mvcc没什么关系，select for update实际上相当于写事务（select的时候加写锁，直到事务结束再释放，update操作本身也是一样的过程，先检索符合条件的记录加锁，再修改并提交，这样才能保证是原子的）</p></li>
<li><p> 分布式环境下的快照读</p>

<p>单点的快照相对来讲比较容易，因为每次可以取一下publish version，来决定什么是可以读取的，但是分布式环境下，每个点读取的时候不能总去看全局publish version(似乎也可以)， 这样本地读取的时候可能由于时间偏移出现全局本地开启事务的时间戳大于全局publish version的问题，</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[cgo实践]]></title>
    <link href="http://cxh.me/2016/04/02/cgo-practice/"/>
    <updated>2016-04-02T16:56:00+08:00</updated>
    <id>http://cxh.me/2016/04/02/cgo-practice</id>
    <content type="html"><![CDATA[<p>  工作里遇到一个问题，想把mysql的crc直接封装一下让go来调用，因为查表的crc计算性能实在是不快，对我们这种文件系统的大报文计算来看，crc容易变成瓶颈。大概性能对比如下：</p>

<pre><code>两线程crc32查表 O2优化
time_elapsed:471.474976s
total_size_m : 200000.000000M
crc rate : 424.200684m/s


两线程crc64指令 O2优化
time_elapsed:24.877853s
total_size_m : 200000.000000M
crc rate : 8039.278809m/s
</code></pre>

<p>  c这一端的计算比较容易，go的crc默认是查表， 所以存在不兼容的问题。出于兼容和性能考虑，用cgo封装一下。</p>

<p>  首先在c语言下把crc打包成lib库，考虑go的移植，直接用静态库比较好。go这边调用如下：</p>

<pre><code>package s3crc

import "unsafe"

// #include &lt;stdlib.h&gt;
// #cgo CFLAGS: -I../../../../src/lib
// #cgo LDFLAGS: -L../../../../src/lib -lcrc
// #include "s3_crc64.h"
import "C"

func s3_crc64(buf string, len int64) uint64 {
    cbuf := C.CString(buf)
    defer C.free(unsafe.Pointer(cbuf))
    return uint64(C.s3_crc64(unsafe.Pointer(cbuf), C.int64_t(len)))
}
</code></pre>

<p>  遇到的坑主要有：</p>

<ol>
<li> cgo不支持ccache，所以这个比较扯。习惯使用ccache的同学（好样的）建议export CC=gcc</li>
<li> 所有类型都需要做转换。go的类型对应到c的类型之后，都在C命名空间下。</li>
<li> 静态库路径需要指明，go的buffer映射到c下面之后，需要考虑释放的问题。参见<a href="https://golang.org/cmd/cgo/" title="Command cgo">文献</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Paxos和Raft的一些思考]]></title>
    <link href="http://cxh.me/2016/03/28/thinkthinking-about-paxos-and-raft/"/>
    <updated>2016-03-28T23:33:00+08:00</updated>
    <id>http://cxh.me/2016/03/28/thinkthinking-about-paxos-and-raft</id>
    <content type="html"><![CDATA[<p>   最近在总结一些协议这么设计的原因，比较杂，纯做记录：</p>

<ol>
<li><p>选主过程相当于Paxos的prepare过程：</p>

<p>选出的Leader得到了多数派的同意，相当于Paxos一阶段完成，由于当前Term下投过票的Server保证不再接受小于等于当前Term的，所以保证了选主最终只能选出一个。</p>

<p>不同于Paxos的地方在于这一轮Term下，follower除非Lease过期，否则不会发起新的选主，也就是发起Epoc更大的提案。Raft可以认为MultiPaxos的一种应用，MultiPaxos可以认为是合并了Prepare阶段的SingleDegreePaxos.</p></li>
<li><p>raft读一致性和选主timeout</p>

<p>raft协议本身由于主只是续约了follower的lease，所以正常情况下follower不会在lease过期前发起新的选主，但是master网络分区情况下，master本身不维护自己的lease，follower lease过期会发起新的选主从而产生新的主。这时候旧主的写一定不能成功，但是旧主的读不受影响。</p>

<p>以前在ob的时候阳老师设计的选主协议里面通过主lease来解决了这个问题，只是当时没体会到原因在这里。协议要求补充限制：主在自己的lease过期后放弃主的身份，主维持心跳的过程中续约follower的lease，根据rpc的返回，只有收到多数派的回应并且term没有更大的才续约自己的lease。新启动的server在follower状态至少等一个lease周期才发起选主，来让可能的旧主过期。</p></li>
<li><p>paxos是两阶段提交的一种场景。</p>

<p>两阶段提交的一阶段也是获得所有参与者的同意。只不过是所有而不是多数派，一阶段通过之后，相当于决议已经形成，所以后一阶段不会产生新的决议。2阶段可以完全异步来做，如果2阶段失败，不影响形成的决议。这意味着两阶段提交是非抢占式的。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[刘鹏《移动时代的营销与变现》笔记]]></title>
    <link href="http://cxh.me/2016/03/28/notes-on-liupeng-report/"/>
    <updated>2016-03-28T23:13:00+08:00</updated>
    <id>http://cxh.me/2016/03/28/notes-on-liupeng-report</id>
    <content type="html"><![CDATA[<p>  上次见刘鹏老师可能还是搜狐实习的时候，后来刘鹏走了，峰扬走了，整个团队改做推荐系统，最后又回到效果广告，算是绕了一个圈吧。买了本计算广告，更多的是给自己一个念想，念念不忘必有回响么。</p>

<p>  主要记录几个知识点或者观点：</p>

<ol>
<li><p> 竞价的历史性作用、gd广告和竞价广告的诞生原因</p>

<p>保量（guarantee delivery）广告相对于品牌广告（CPT），主要解决了流量浪费的问题，CPM的售卖方式相对增加了广告流量的利用率（比如按照性别的售卖，大致可以增加20-25%的收益）。然而保量广告相对来讲对流量的利用并不极致，大部分gd系统都面临超卖或者保守售卖的问题，可能会导致补量或者浪费，在线流量分配和优化也是个比较复杂的问题。所以才有了竞价广告，根据<a href="https://www.zhihu.com/question/19804990" title="怎样向非专业人士专业地解释「纳什均衡」？">Nash均衡</a>，广告价格是出价方博弈的结果。这样就可以让广告效益最大化，区分优质流量，同时长尾的流量也有变现的机会。</p>

<p>当然也就引入了程序化交易。程序化交易是工业化的结果，但是对于广告来讲，良莠不齐的广告对于场景融入是非常不利的。程序化交易在移动时代带来了更不好的用户体验。</p></li>
<li><p> 搜索广告的场景和精妙之处</p>

<p>搜索广告实现了两点最精巧的地方：精确判断用户意图，跟媒体内容完美融入，所以历来是兵家必争之地。</p></li>
<li><p> 移动广告、gps定位、地理位置</p>

<p>移动时代，广告不能照搬PC时代的经验。移动设备屏幕上广告的体验是很差的。移动时代对于用户意图的判断实际上是更精准了，比如可以通过GPS等判断用户所处的位置，推送更符合场景的广告。但是广告体验就更加困难了，这是有利有弊的地方。</p></li>
<li><p> O2O是潜在的广告市场</p>

<p>O2O商家是之前几乎不可能成为广告主的一个群体。O2O广告有相当的地域要求，所以对Targeting的要求更高，相对PC时代，移动时代才是O2O广告能发力的地方。智能手机的普及提供了更精准的Targeting，使这部分人群有可能成为潜在广告主。</p></li>
</ol>


<h3>Bibliography:</h3>

<p>  [1] 怎样向非专业人士专业地解释「纳什均衡」？, <a href="https://www.zhihu.com/question/19804990">https://www.zhihu.com/question/19804990</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[记录一个网络库设计的bug]]></title>
    <link href="http://cxh.me/2016/03/25/netlib-bug-analysis/"/>
    <updated>2016-03-25T00:14:00+08:00</updated>
    <id>http://cxh.me/2016/03/25/netlib-bug-analysis</id>
    <content type="html"><![CDATA[<p>   今天遇到一个设计上没考虑好的问题，记录一下。</p>

<p>   之前Libeasy的逻辑如果一个连接上有超时的报文的话，整个连接会destroy掉。考虑网络拥塞的情况，如果AB两个报文同时在等待发送，A报文先进入发送队列（链表，非TCP发送buffer），B后进入，而A超时时间长，B立即超时，那么清理掉B的待发送报文的时候，如果destroy掉连接，那么本来可以发送出去的A报文就被强制失败了。</p>

<p>   考虑这种情况做了一点修改，让超时的报文被清理掉的时候不会destroy连接。这样编码的时候需要指定一个报文被编码出来的buffer是属于哪个会话（session）的，同时记录一下每个session对应的最后一个buffer位置。清理的时候可以从上述位置回溯到不属于当前session的buffer或者到头部为止。看似没啥问题。今天发现了如下的bug：</p>

<p>   考虑如果一个会话编码的多个buffer（或者一个buffer）被部分发送完毕（write返回大小为准），这时候会话超时，这个会话所属的所有编码过的buffer都被干掉，但是连接并没有被destroy，之后的报文继续发送的话，客户端实际上收到了不完整的报文，相当于之后的TCP流都错位了。这种情况下，destroy连接是明显更安全的做法。</p>

<p>   所以还是要考虑周全啊。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于最近的一些事情]]></title>
    <link href="http://cxh.me/2016/03/18/farwell-yanpo/"/>
    <updated>2016-03-18T23:47:00+08:00</updated>
    <id>http://cxh.me/2016/03/18/farwell-yanpo</id>
    <content type="html"><![CDATA[<p>   最近其实是乏善可陈的，项目差不多写完，修修补补，提升下性能。其他的事情诸多不顺，看房价蹭蹭的涨，看工资慢慢的爬，感情纠结一团，其他的么，牙疼，估计牙周炎犯了。</p>

<p>   然后今天炎泼说要走了，陈闯二话没说也跟着走了，先知先觉的后知后觉的都有各自的想法，只是我比较懵逼，可能最近事情多了，精力都不在这上面。每个人有自己的选择，目前看互联网差不多进入稳定期了，风口还有，但是能飞起来的猪不多了，剩下的人，要么在大公司朝九晚五，要么在创业公司等期权等上市，少数人还追求着理想，不过最后如果没有回到前面两个状态的话，一般是创业去了。</p>

<p>   工作几年觉得介于目的性明确和不明确之间吧。做技术的明显分了两派，以KPI为核心的和以兴趣为核心的，很多时候这两个不是不兼容的。目的明确的，一切跟个人发展不相关的都推掉，目的不明确的，还是选择follow heart多一点。没有褒贬，个人选择而已。最好是大方向下，找点自己喜欢做的，否则工作容易无趣啊。不过这种坑也似乎不好找，当然不排除有人兴趣特别，比如我就是向往资产阶级腐朽堕落的生活方式&hellip;</p>

<p>   博客好久不写了。感觉技术文章吧，一旦开头容易虎头蛇尾，扯扯淡吧，微博微信朋友圈足够了。无聊的时候，也就是刷刷知乎找朋友扯扯淡，看看有没有新梗，翻墙看看。最近整个社会都压抑吧，连门缝里塞小纸片的都少了，可见人民群众都进入到了一种就这样吧还能咋滴的状态里。</p>

<p>   所以我还是一直觉得要找到一点精神的寄托，哪怕是打游戏呢（没鄙视的意思打游戏挺好）。最近听许巍的新歌《生活不止眼前的苟且》，觉得似乎又回到校园了，回到北航的主楼，回到绿园的树荫和荷塘，想起陈旧的宿舍楼里阳光洒在斑驳的墙面，想起清华园的午后，想起月下的荷塘，想起东门外五道口的火车道&hellip;</p>

<pre><code>    生活不止眼前的苟且
    还有诗和远方的田野
    你赤手空拳来到人世间
    为找到那片海不顾一切
</code></pre>

<p>   所以我这么感性的人是不是应该去搞音乐&hellip;毕竟钢琴比键盘也就是多了几十个键而已，用惯了Emacs的话，和弦弹起来也没什么按不过来的。</p>

<p>   都是幻觉，都是幻觉&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[go生成xml的时候特殊字符转义的问题]]></title>
    <link href="http://cxh.me/2016/03/18/go-xml-escape/"/>
    <updated>2016-03-18T17:43:00+08:00</updated>
    <id>http://cxh.me/2016/03/18/go-xml-escape</id>
    <content type="html"><![CDATA[<p>  最近在做http返回的时候发现go的xml生成（marshal）会把引号转义，如下：</p>

<pre><code>    &lt;?xml version="1.0" encoding="UTF-8"?&gt;

    &lt;Part&gt;
      &lt;PartNumber&gt;1&lt;/PartNumber&gt;
      &lt;LastModified&gt;2016-03-18T08:24:25.000Z&lt;/LastModified&gt;
      &lt;ETag&gt;&amp;#34;0c78aef83f66abc1fa1e8477f296d394&amp;#34;&lt;/ETag&gt;
      &lt;Size&gt;12121&lt;/Size&gt;
    &lt;/Part&gt;     
</code></pre>

<p>  看了下源码，marshal函数的实现就会默认转义。这样就只能加一个Type，不直接用string，然后定义这个Type的marshl函数。上网搜了一下发现可以找个方法绕过去：struct的修饰可以指明当前的struct field不做转义，直接输出。</p>

<pre><code>    type Part struct {
         XMLName      xml.Name `xml:"Part"`
         PartNumber   int
         LastModified string
         ETag         string `xml:",innerxml"`
         Size         int64
    }
</code></pre>

<p>  这样可以直接在序列化的时候传自己拼成的ETag值。比如：</p>

<pre><code>     Part{PartNumber: 1,
         LastModified: S3TimeFormat(GetCurrentTime()),
         ETag:         `&lt;ETag&gt;"acbd18db4cc2f85cedef654fccc4a4d8"&lt;/ETag&gt;`,
         Size:         12121}
</code></pre>

<p>  输出结果满足要求：</p>

<pre><code>    &lt;?xml version="1.0" encoding="UTF-8"?&gt;

    &lt;Part&gt;
      &lt;PartNumber&gt;1&lt;/PartNumber&gt;
      &lt;LastModified&gt;2016-03-18T08:32:39.000Z&lt;/LastModified&gt;&lt;ETag&gt;"acbd18db4cc2f85cedef654fccc4a4d8"&lt;/ETag&gt;
      &lt;Size&gt;12121&lt;/Size&gt;
    &lt;/Part&gt;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[vim编译错误：PyUnicodeUCS4_AsEncodedString]]></title>
    <link href="http://cxh.me/2016/03/06/vim-comple-error-with-pyunicodeucs4-asencodedstring/"/>
    <updated>2016-03-06T14:45:00+08:00</updated>
    <id>http://cxh.me/2016/03/06/vim-comple-error-with-pyunicodeucs4-asencodedstring</id>
    <content type="html"><![CDATA[<p>  换了个ubuntu的环境想编译一下vim，为了防止不兼容手动编译了python2.7，之后把改过的vim源码放上去编译发现有问题：</p>

<pre><code>undefined symbol: PyUnicodeUCS4_AsEncodedString
</code></pre>

<p>  于是换回标准的vim源码还是一样的问题，我擦嘞。上网搜一下说Python模式是UnicodeUCS2的支持，从源码里面直接grep一下这个函数发现是有的：</p>

<pre><code>Include/unicodeobject.h:# define PyUnicode_AsEncodedString PyUnicodeUCS4_AsEncodedString
</code></pre>

<p>  那只可能是没有开启编译选项了，./configure &mdash;help发现有如下一项：</p>

<pre><code>  --enable-unicode[=ucs[24]]
                      Enable Unicode strings (default is ucs2)
</code></pre>

<p>  configure到ucs4重新编译python2.7，完美。没毛病。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[libev源码分析]]></title>
    <link href="http://cxh.me/2015/12/19/libev-source-analysis/"/>
    <updated>2015-12-19T16:29:00+08:00</updated>
    <id>http://cxh.me/2015/12/19/libev-source-analysis</id>
    <content type="html"><![CDATA[<p>  本文源码以libev4.20为准，其他版本大同小异。</p>

<p>  libev是广泛使用的事件库，是一个功能强大的reactor，可以把Timer、IO、进程线程事件放在一个统一的框架下进行管理。如果有其他的事件触发需求也可以改libev源码把该事件加入libev的框架中（当前前提是得理解libev的设计）。有文章说libev性能比libevent好，没实验过，但是从源码角度看，libev要更简洁，当然更费解一点。作者为了追求代码的整洁和统一使用了大量的宏，造成了阅读的不便。这里我们从宏观分析一下libev的设计实现，然后穿插分析一些小的trick。旨在学习总结libev设计中优雅的地方。</p>

<h3>基本概念</h3>

<p>  首先是一些主要的概念和数据结构。</p>

<p>  libev通过定义watcher来关注一个事件，并且把事件类型和对应的毁回调函数关联起来。libev定义了多种事件类型，同时可以在框架中自己添加感兴趣的事件，libev保证了事件触发的顺序性，并在多线程环境下保证事件的串行触发。</p>

<p>  每一种类型的watcher都包含几个基本的成员，通过EV_WATCHER和EV_WATCHER_LIST宏实现。EV_WATCHER_LIST比EV_WATCHER多了一个纸箱下一个watcher的指针。EV_WATCHER_TIMER是定时器的基类，多一个timestamp。这几个宏这里留一个小的trick分析，在后面阐述。</p>

<!--more-->


<pre><code>/* shared by all watchers */
#define EV_WATCHER(type)            \
  int active; /* private */         \
  int pending; /* private */            \
  EV_DECL_PRIORITY /* private */        \
  EV_COMMON /* rw */                \
  EV_CB_DECLARE (type) /* private */

#define EV_WATCHER_LIST(type)           \
  EV_WATCHER (type)             \
  struct ev_watcher_list *next; /* private */

#define EV_WATCHER_TIME(type)           \
  EV_WATCHER (type)             \
  ev_tstamp at;     /* private */
</code></pre>

<p>   举一个例子，IO事件watcher：ev_io</p>

<pre><code>/* invoked when fd is either EV_READable or EV_WRITEable */
/* revent EV_READ, EV_WRITE */
typedef struct ev_io
{
  EV_WATCHER_LIST (ev_io)

  int fd;     /* ro */
  int events; /* ro */
} ev_io;
</code></pre>

<p>  可以看到ev_io相当于继承了基类ev_watcher_list，并派生出自己的成员，fd和events，分别用来存储文件描述符和事件标识。类似的watcher有：</p>

<ol>
<li> 基类ev_watcher，ev_watcher_list, ev_watcher_time.</li>
<li> io：ev_io</li>
<li> 周期触发定时器：ev_periodic</li>
<li> 定时器：ev_timer</li>
<li> 信号：ev_signal</li>
<li> 子进程：ev_child</li>
<li> 文件stat：ev_stat</li>
<li> 一些内部流程watcher：ev_idle，ev_prepare，ev_check， ev_fork, ev_cleanup</li>
<li> 异步触发：ev_async</li>
</ol>


<h3>使用流程</h3>

<p>  libev库的基本使用流程是：</p>

<ol>
<li> 生成一个循环(loop)对象，单线程情况下直接使用default_loop，多线程的情况下使用ev_loop_new来创建。</li>
<li> 调用ev_xx_init先注册一个感兴趣的watcher。把这个watcher跟事件、回调关联起来。</li>
<li> 调用ev_xx_start把事件添加到loop的待处理（后述）列表中。</li>
<li> 调用ev_run执行循环。</li>
</ol>


<p>  一个简单的使用例程如下（来自官方sample，可见官方风格是大括号换行的&hellip;.鄙视）：</p>

<pre><code>// a single header file is required
#include &lt;ev.h&gt;

#include &lt;stdio.h&gt; // for puts

// every watcher type has its own typedef'd struct
// with the name ev_TYPE
ev_io stdin_watcher;
ev_timer timeout_watcher;

// all watcher callbacks have a similar signature
// this callback is called when data is readable on stdin
static void
stdin_cb (EV_P_ ev_io *w, int revents)
{
  puts ("stdin ready");
  // for one-shot events, one must manually stop the watcher
  // with its corresponding stop function.
  ev_io_stop (EV_A_ w);

  // this causes all nested ev_run's to stop iterating
  ev_break (EV_A_ EVBREAK_ALL);
}

// another callback, this time for a time-out
static void
timeout_cb (EV_P_ ev_timer *w, int revents)
{
  puts ("timeout");
  // this causes the innermost ev_run to stop iterating
  ev_break (EV_A_ EVBREAK_ONE);
}

int
main (void)
{
  // use the default event loop unless you have special needs
  struct ev_loop *loop = EV_DEFAULT;

  // initialise an io watcher, then start it
  // this one will watch for stdin to become readable
  ev_io_init (&amp;stdin_watcher, stdin_cb, /*STDIN_FILENO*/ 0, EV_READ);
  ev_io_start (loop, &amp;stdin_watcher);

  // initialise a timer watcher, then start it
  // simple non-repeating 5.5 second timeout
  ev_timer_init (&amp;timeout_watcher, timeout_cb, 5.5, 0.);
  ev_timer_start (loop, &amp;timeout_watcher);

  // now wait for events to arrive
  ev_run (loop, 0);

  // break was called, so exit
  return 0;
}
</code></pre>

<h3>实现分析：</h3>

<p>  下面我们针对上述程序分析一下libev的实现。</p>

<p>  首先直接采用了default_loop，这里没有使用多线程支持。如果需要开启的话，记得define一下EV_MULTIPLICITY，源码中有大量的对EV_MULTIPLICITY的判断，如果define了则增加一个loop入参来指定运行的线程，否则就直接用默认的。源码实现如下（这里只给出了ev_loop定义）：</p>

<pre><code>#if EV_MULTIPLICITY

  struct ev_loop
  {
    ev_tstamp ev_rt_now;
    #define ev_rt_now ((loop)-&gt;ev_rt_now)
    #define VAR(name,decl) decl;
      #include "ev_vars.h"
    #undef VAR
  };
  #include "ev_wrap.h"

  static struct ev_loop default_loop_struct;
  EV_API_DECL struct ev_loop *ev_default_loop_ptr = 0; /* needs to be initialised to make it a definition despite extern */

#else

  EV_API_DECL ev_tstamp ev_rt_now = 0; /* needs to be initialised to make it a definition despite extern */
  #define VAR(name,decl) static decl;
    #include "ev_vars.h"
  #undef VAR

  static int ev_default_loop_ptr;

#endif
</code></pre>

<p>  var这里留一个小trick分析，在后面来阐述。</p>

<p>  sample之后调用了两个init来关联事件、watcher和回调函数。对应的定义如下：</p>

<pre><code>/* these may evaluate ev multiple times, and the other arguments at most once */
/* either use ev_init + ev_TYPE_set, or the ev_TYPE_init macro, below, to first initialise a watcher */
#define ev_init(ev,cb_) do {            \
  ((ev_watcher *)(void *)(ev))-&gt;active  =   \
  ((ev_watcher *)(void *)(ev))-&gt;pending = 0;    \
  ev_set_priority ((ev), 0);            \
  ev_set_cb ((ev), cb_);            \
} while (0)

#define ev_io_set(ev,fd_,events_)            do { (ev)-&gt;fd = (fd_); (ev)-&gt;events = (events_) | EV__IOFDSET; } while (0)
#define ev_timer_set(ev,after_,repeat_)      do { ((ev_watcher_time *)(ev))-&gt;at = (after_); (ev)-&gt;repeat = (repeat_); } while (0)

#define ev_io_init(ev,cb,fd,events)          do { ev_init ((ev), (cb)); ev_io_set ((ev),(fd),(events)); } while (0)
#define ev_timer_init(ev,cb,after,repeat)    do { ev_init ((ev), (cb)); ev_timer_set ((ev),(after),(repeat)); } while (0)
</code></pre>

<p>  可以看到，每种类型的init都是定义了一些赋值操作，由于各种watcher都是从ev_watcher &ldquo;派生&rdquo; 而来的，所以可以用ev_watcher向上转换来访问公共成员。这里只是定义了对象，不涉及事件的注册等操作。</p>

<p>  之后sample通过调用xx_start把事件添加到了关注列表中。ev_io_start的源码如下：</p>

<pre><code>void noinline
ev_io_start (EV_P_ ev_io *w) EV_THROW
{
  int fd = w-&gt;fd;

  if (expect_false (ev_is_active (w)))//当前watcher是否已经active
    return;

  assert (("libev: ev_io_start called with negative fd", fd &gt;= 0));
  assert (("libev: ev_io_start called with illegal event mask", !(w-&gt;events &amp; ~(EV__IOFDSET | EV_READ | EV_WRITE))));

  EV_FREQUENT_CHECK;//周期性的检查

  ev_start (EV_A_ (W)w, 1);
  array_needsize (ANFD, anfds, anfdmax, fd + 1, array_init_zero);
  wlist_add (&amp;anfds[fd].head, (WL)w);//添加到watcher list

  /* common bug, apparently */
  assert (("libev: ev_io_start called with corrupted watcher", ((WL)w)-&gt;next != (WL)w));

  fd，change (EV_A_ fd, w-&gt;events &amp; EV__IOFDSET | EV_ANFD_REIFY);//加入事件变更
  w-&gt;events &amp;= ~EV__IOFDSET;

  EV_FREQUENT_CHECK;//周期检查
}
</code></pre>

<p>  代码主要的逻辑在三个地方，ev_start、wlist_add和fd_change。ev_start的比较简单，主要是标记了一下当前watcher已经actived，这是所有的xx_start函数都有的逻辑。</p>

<pre><code>  inline_speed void
ev_start (EV_P_ W w, int active)
{
  pri_adjust (EV_A_ w);
  w-&gt;active = active;
  ev_ref (EV_A);
}
</code></pre>

<p>  之后的部分每个不同的watcher实现不同。针对io_watcher，由于fd分配是连续的，所以这个长度可以进行大小限制的，我们用一个连续的数组来存储fd/watcher信息，如<a href="https://cnodejs.org/topic/4f16442ccae1f4aa270010a3" title="libev 设计分析">下图所示</a>，用anfd[fd] 就可以找到对应的fd/watcher信息，如果遇到anfd超出我们的buffer长度情形，可以动态扩容。这里直接用了文献2里面的图。</p>

<p>  <img class="img-polaroid center" src="http://static.data.taobaocdn.com/up/nodeclub/2011/09/seQHQpwHRHOicrTFuDaCs8w.png"></p>

<p>  wlist_add完成向anfd数组对应位置的链表增加事件的工作。更详细的过程可以参考文献2。</p>

<p>  最后fd_change完成增加事件变更的任务。libev会根据之前的wlist来判断一个事件是否需要调用对应的处理函数向系统添加监听，比如针对epoll，如果第一次在一个watcher(fd）上调用io_start，那么fdchanges数组中会增加一项，表明下个事件循环周期内需要调用epoll_ctl增加监听。如果之前已经有对应的事件监听存在，则判断是否要替换，不需要再调用epoll_ctl更改epoll的事件注册。源码如下：</p>

<pre><code>/* something about the given fd changed */
inline_size void
fd_change (EV_P_ int fd, int flags)
{
  unsigned char reify = anfds [fd].reify;
  anfds [fd].reify |= flags;

  if (expect_true (!reify))
    {
      ++fdchangecnt;
      array_needsize (int, fdchanges, fdchangemax, fdchangecnt, EMPTY2);
      fdchanges [fdchangecnt - 1] = fd;
    }
}
</code></pre>

<p>  到底位置libev只是完成了一些初始化操作，表明需要对什么事件进行什么处理，但事件流程并没有run起来，最后需要做的是调用ev_run来起线程，并进入事件循环。整个ev_run函数较长，大概有两百多行，这里就不列出代码了，只把程序的主要逻辑列出来。</p>

<pre><code>  int
ev_run (EV_P_ int flags)
{
  ...
  do
    {
      ...
      //如果这个进程是新fork出来的，执行ev_fork事件的回调
      ...
      //执行ev_prepare回调，也就是每次poll前执行的函数
      ...
      //执行监听有改变的事件
      ...
      //计算poll应该等待的时间,这个时间和设置以及定时器超时时间有关
      ...
      //调用后台I/O复用端口等待事件触发
      backend_poll (EV_A_ waittime);
      ...
      //将定时器事件放入pending数组中
      ...
      //将ev_check事件翻入pending数组中
      ...
      //执行pending数组中所有的回调
      EV_INVOKE_PENDING;
    }
  while (调用了stop);
}
</code></pre>

<p>  backend_poll封装了不同系统的多路复用机制，在不同的情况下会映射成不同的实现，如epoll、kequque等。对于epoll而言，在每次epoll_wait之前会执行fd_reify(loop)。 fd_reify中会遍历fdchanges数组，把对fd事件的修改通过调用epoll_modify来做真正的修改，这里才真正完成了事件监听向系统的注册。这里有个小的trick再后面分析。</p>

<p>  具体的代码中，程序使用queue_events将要运行的事件放入一个叫做pending的二维数组中，其第一维是优先级，第二维是动态分配的，存放具体事件。之后程序会在适当的地方调用宏EV_INVOKE_PENDING，将pending数组中的事件按优先级从高到低依次执行。</p>

<p>  基本流程图可以看这里，转自<a href="http://csrd.aliapp.com/?p=1604" title="libev ev_io源码分析">阿里核心系统团队博客</a>：</p>

<p>  <img class="img-polaroid center" src="http://csrd.aliapp.com/wp-content/plugins/libev_loop2.png"></p>

<h3>一些技巧</h3>

<ol>
<li><p>首先是通过define来模拟了继承。libev用宏定义了ev_watcher等基类的成员，实现派生类的时候只需要先用宏把公共成员包含进来，然后定义各个子类自己的成员即可。这种技巧也广泛用在其他一些开源项目中。</p></li>
<li><p>通过重新define var关键字和重新包含vars头文件的方式，可以把一组变量变换成不同的形式：</p>

<pre><code> #define VAR(name,decl) decl;
   #include "ev_vars.h"
 #undef VAR

 #define VAR(name,decl) static decl;
   #include "ev_vars.h"
 #undef VAR
</code></pre>

<p> 这个技巧也被用在s3_error.h里面，用来同时生成一个错误码的定义和其字符串描述。</p></li>
<li><p>最后编译libev的时候会发现像epoll.c poll.c等平台相关的backend定义实际上没有加入Makefile。libev实现的时候其实直接在源码里面根据define来包含了c文件。大部分时候我们都是只include头文件，所以这里在使用的时候需要稍加注意。</p></li>
</ol>


<h3>总结</h3>

<p>libev虽然代码比较晦涩，但是实现还是很清楚的，设计思想对于实现底层系统很有启发，值得仔细研读。时间有限，只涵盖了一下基本框架，如果有兴趣还是自己改写一下，会更有收获。</p>

<h3>参考文献:</h3>

<blockquote><p>[1] libev ev_io源码分析, <a href="http://csrd.aliapp.com/?p=1604">http://csrd.aliapp.com/?p=1604</a></p>

<p>[2] libev 设计分析, <a href="https://cnodejs.org/topic/4f16442ccae1f4aa270010a3">https://cnodejs.org/topic/4f16442ccae1f4aa270010a3</a></p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ssh绑定其他端口]]></title>
    <link href="http://cxh.me/2015/11/01/ssh-bind-other-port/"/>
    <updated>2015-11-01T14:14:00+08:00</updated>
    <id>http://cxh.me/2015/11/01/ssh-bind-other-port</id>
    <content type="html"><![CDATA[<p>  首先修改/ssh/sshd_config，把Port 22解注释，然后加一行Port xx。之后修改 /etc/sysconfig/iptables，加入该端口的Rules:</p>

<pre><code>-A INPUT -m state --state NEW -m tcp -p tcp --dport xx -j ACCEPT  
</code></pre>

<p>  重启即可。</p>

<pre><code>/etc/init.d/sshd restart
</code></pre>

<p>  这么做的目的是如果出现问题，还有一个端口可以上去修改。登录的时候需要对应的指定一下端口：</p>

<pre><code>ssh -p xx user@host
scp -P xx ... user@host
</code></pre>

<p>  补充两个SSH技巧：</p>

<ol>
<li><p> 客户端配置中转，主要是通过跳板机登录：</p>

<pre><code>Host xx
HostName 192.168.1.1
User xx
ProxyCommand ssh -q xxx@login2.xxx.xx nc %h %p
</code></pre></li>
<li><p> 保持会话。 ssh会在.ssh目录下生成一个会话选项，下次登录同一个server公用会话，不需要验证。</p>

<pre><code>Host *
ControlMaster auto
ControlPath ~/.ssh/master-%r@%h:%p
</code></pre>

<p>上面会话共享，所以不能关闭会话。可以通过 <code>ssh -fN xxx</code> 把第一个会话放到后台不退出</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RBTools兼容的问题]]></title>
    <link href="http://cxh.me/2015/08/31/rbtools-compatible-problems/"/>
    <updated>2015-08-31T15:26:00+08:00</updated>
    <id>http://cxh.me/2015/08/31/rbtools-compatible-problems</id>
    <content type="html"><![CDATA[<p>  某天ReviewBoard客户端突然用不了，使用    <code>rbt post</code>的时候报错:</p>

<pre><code>from six.moves.urllib.parse import quote
ImportError: No module named urllib.parse
</code></pre>

<p>  乍一看以为什么包被卸载了。于是pip install six &mdash;upgrade，无果。pip uninstall RBTools再重新安装RBTools，也无效。</p>

<p>  查了一下six是python2、python3的兼容包，直接修改源码，不要兼容了，发现用到的地方好多，改不过来（ps，兼容python2、python3真不容啊）。</p>

<p>  查看six的版本，发现跟本地一样的，本地没什么问题。说明不是six的问题。直接在命令行from six.moves.urllib.parse import quote，发现本地ok，服务器上不行。</p>

<p>  这就比较扯了，同样的版本，本地可以服务器不行。直接卸了重装：</p>

<pre><code>pip uninstall six #注，这里卸载了1.9的six
pip uninstall six #日，还有一个1.2的six，不知道pip list为啥显示不出来。
pip install six
easy_install RBTools
</code></pre>

<p>  然后就ok了。所以还是要习惯在virtualenv下搞啊&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[paxos的一些case分析]]></title>
    <link href="http://cxh.me/2015/08/28/paxos-case-analysis/"/>
    <updated>2015-08-28T11:34:00+08:00</updated>
    <id>http://cxh.me/2015/08/28/paxos-case-analysis</id>
    <content type="html"><![CDATA[<p>acceptor: a([epoc:4, value:n])  b[epoc:3,value:y]  c[epoc:6,:value:y]</p>

<p>proposor:  x5, x7,   (x4, x3, x6)</p>

<p>prepare:x5[a, b], x7[b, c]</p>

<p>commit:x[4,n] y[6, y]</p>

<p>一共有5个proposer,</p>

<p>1）初始时 x4 (prepare)&ndash;> a, x3 (prepare)&ndash;> b,x6 (prepare)&ndash;> c,
2） x4, x3, x6 挂掉
3）x5(prepare)&ndash;> a, b
4）x5(commit[epoc:4, value:n])&ndash;>a, b
5) x7(prepare) &ndash;>b, c
6) x7(commit[epoc:6, value:y])&ndash;>b, c</p>
]]></content>
  </entry>
  
</feed>
